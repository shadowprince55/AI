### Popular CNN architectures
---
* Alexnet:
    * AlexNet consists of five convolutional layers followed by three fully connected layers.
    * It introduced the ReLU activation function, dropout, and data augmentation techniques.

-----
* Resnet:
    * It was introduced to address the problem of vanishing gradients in very deep networks.
    * ResNet introduces the concept of residual blocks, which contain skip connections (shortcut connections) that allow gradients to flow more easily during training.
    * The architecture can be extremely deep (hundreds of layers) without suffering from the vanishing gradient problem.
